{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dc3ea4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.16.12.129:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "146e025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('deep_learning').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "259c1dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dl_data.csv into hadoop in the named folder 'user1'\n",
    "\n",
    "df = spark.read.csv('/user1/fer2013.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "69b31830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emotion: integer (nullable = true)\n",
      " |-- pixels: string (nullable = true)\n",
      " |-- Usage: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the structure of schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a1c115b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------+\n",
      "|emotion|              pixels|   Usage|\n",
      "+-------+--------------------+--------+\n",
      "|      0|70 80 82 72 58 58...|Training|\n",
      "|      0|151 150 147 155 1...|Training|\n",
      "|      2|231 212 156 164 1...|Training|\n",
      "|      4|24 32 36 30 32 23...|Training|\n",
      "|      6|4 0 0 0 0 0 0 0 0...|Training|\n",
      "+-------+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e450134c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (35887, 3)\n"
     ]
    }
   ],
   "source": [
    "# print of data shape\n",
    "print('Shape of dataset:',(df.count(),len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "169188c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 93:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------------+-----------+\n",
      "|summary|           emotion|              pixels|      Usage|\n",
      "+-------+------------------+--------------------+-----------+\n",
      "|  count|             35887|               35887|      35887|\n",
      "|   mean|3.3232646919497313|                null|       null|\n",
      "| stddev|1.8738187592999593|                null|       null|\n",
      "|    min|                 0|0 0 0 0 0 0 0 0 0...|PrivateTest|\n",
      "|    max|                 6|99 99 99 99 101 1...|   Training|\n",
      "+-------+------------------+--------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2233efde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emotion', 'pixels', 'Usage']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "26c6d2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|      Usage|\n",
      "+-----------+\n",
      "|   Training|\n",
      "| PublicTest|\n",
      "|PrivateTest|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "uniqe_usages = df.select(\"Usage\").distinct()\n",
    "uniqe_usages.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bdaf6a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Define mapping of emotions to labels\n",
    "emotion_mapping = {\n",
    "    0: \"Angry\",\n",
    "    1: \"Disgust\",\n",
    "    2: \"Fear\",\n",
    "    3: \"Happy\",\n",
    "    4: \"Sad\",\n",
    "    5: \"Surprise\",\n",
    "    6: \"Neutral\"\n",
    "}\n",
    "\n",
    "# Create 'label' column based on 'emotion' column\n",
    "emotion_to_label_udf = udf(lambda emotion: emotion_mapping.get(emotion, \"Unknown\"), StringType())\n",
    "\n",
    "df = df.withColumn(\"label\", emotion_to_label_udf(df[\"emotion\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b640930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"pixels\", F.split(df[\"pixels\"], \" \").cast(\"array<int>\").alias(\"pixels\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6be19def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emotion: integer (nullable = true)\n",
      " |-- pixels: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      " |-- Usage: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "69208595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "\n",
    "@udf(ArrayType(FloatType()))\n",
    "def normalize_pixels(pixels):\n",
    "    return [float(pixel) / 255.0 for pixel in pixels]\n",
    "\n",
    "df = df.withColumn(\"pixels\", normalize_pixels(df[\"pixels\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "70dbd04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------+--------+\n",
      "|emotion|              pixels|   Usage|   label|\n",
      "+-------+--------------------+--------+--------+\n",
      "|      0|[0.27450982, 0.31...|Training|   Angry|\n",
      "|      0|[0.5921569, 0.588...|Training|   Angry|\n",
      "|      2|[0.90588236, 0.83...|Training|    Fear|\n",
      "|      4|[0.09411765, 0.12...|Training|     Sad|\n",
      "|      6|[0.015686275, 0.0...|Training| Neutral|\n",
      "|      2|[0.21568628, 0.21...|Training|    Fear|\n",
      "|      4|[0.078431375, 0.0...|Training|     Sad|\n",
      "|      3|[0.3019608, 0.305...|Training|   Happy|\n",
      "|      3|[0.33333334, 0.32...|Training|   Happy|\n",
      "|      2|[1.0, 0.99607843,...|Training|    Fear|\n",
      "|      0|[0.11764706, 0.09...|Training|   Angry|\n",
      "|      6|[0.15294118, 0.29...|Training| Neutral|\n",
      "|      6|[0.85882354, 0.83...|Training| Neutral|\n",
      "|      6|[0.5803922, 0.564...|Training| Neutral|\n",
      "|      3|[0.015686275, 0.0...|Training|   Happy|\n",
      "|      5|[0.41960785, 0.41...|Training|Surprise|\n",
      "|      3|[0.05490196, 0.05...|Training|   Happy|\n",
      "|      2|[1.0, 1.0, 1.0, 1...|Training|    Fear|\n",
      "|      6|[0.5254902, 0.486...|Training| Neutral|\n",
      "|      4|[0.85882354, 0.75...|Training|     Sad|\n",
      "+-------+--------------------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8257eb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304\n"
     ]
    }
   ],
   "source": [
    "sample_pixels = df.select(\"pixels\").first()[\"pixels\"]\n",
    "print(len(sample_pixels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2ed2449f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------+-------+\n",
      "|emotion|              pixels|   Usage|  label|\n",
      "+-------+--------------------+--------+-------+\n",
      "|      0|[0.27450982, 0.31...|Training|  Angry|\n",
      "|      0|[0.5921569, 0.588...|Training|  Angry|\n",
      "|      2|[0.90588236, 0.83...|Training|   Fear|\n",
      "|      4|[0.09411765, 0.12...|Training|    Sad|\n",
      "|      6|[0.015686275, 0.0...|Training|Neutral|\n",
      "+-------+--------------------+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6c3978ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.filter(df[\"Usage\"] == \"Training\")\n",
    "test_df = df.filter(df[\"Usage\"] == \"PrivateTest\")\n",
    "val_df = df.filter(df[\"Usage\"] == \"PublicTest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b376f592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_df: (28709, 4)\n",
      "Shape of test_df: (3589, 4)\n",
      "Shape of val_df: (3589, 4)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of train_df:',(train_df.count(),len(train_df.columns)))\n",
    "print('Shape of test_df:',(test_df.count(),len(test_df.columns)))\n",
    "print('Shape of val_df:',(val_df.count(),len(val_df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2b2ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
